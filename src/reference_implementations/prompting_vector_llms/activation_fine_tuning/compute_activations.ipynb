{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import datasets\n",
    "import kscope\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '66b0b397-cad3-4bcc-a8a8-67c63a10b726',\n",
       "  'name': 'llama2-13b',\n",
       "  'state': 'ACTIVE'},\n",
       " {'id': '66cf42ea-0b5b-4638-b60e-50d771a022b5',\n",
       "  'name': 'llama2-7b',\n",
       "  'state': 'ACTIVE'},\n",
       " {'id': 'a8c2cc41-f9b0-4c4e-9b9e-9189f5dd7331',\n",
       "  'name': 'falcon-7b',\n",
       "  'state': 'ACTIVE'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish a client connection to the kscope service\n",
    "client = kscope.Client(gateway_host=\"llm.cluster.local\", gateway_port=3001)\n",
    "client.model_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.load_model(\"llama2-13b\")\n",
    "# If this model is not actively running, it will get launched in the background.\n",
    "# In this case, wait until it moves into an \"ACTIVE\" state before proceeding.\n",
    "while model.state != \"ACTIVE\":\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Generation (__NOTE__ This takes a very long time to run (An hour or two)!)\n",
    "\n",
    "In this notebook, we're going to extract the activations from the final non-pad token of LLaMA-13B for different sets of text inputs. This is done (on the back-end) by inserting hooks into the model that allow for extraction of the model's intermediate latent representations. In this notebook, we'll vary both the layer we extract information from and the input itself to consider the affect that these choices have on the performance of a downstream task. In this case, we'll consider a sampling of the IMDB sentiment analysis task to probe these choices.\n",
    "\n",
    "To start, we need to define a configuration for the model generation. Because we only care about the activations of our input, the configuration is less important. The only thing we really need to do is set the `max_tokens` to 1 so that we don't have to worry about indexing into the right spot in our activation matrix. That is, the activations we care about will just occur in the last slot of the tensor. For a discussion of the configuration parameters see [CONFIG_README.md](../../prompting_vector_llms/CONFIG_README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\"max_tokens\": 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Generation \n",
    "\n",
    "Activation generation is quite easy. We can use the client to query the remote model and explore the various modules. Here, we are listing only the last 10 layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok_embeddings',\n",
       " 'layers',\n",
       " 'layers.0',\n",
       " 'layers.0.attention',\n",
       " 'layers.0.attention.wq',\n",
       " 'layers.0.attention.wk',\n",
       " 'layers.0.attention.wv',\n",
       " 'layers.0.attention.wo',\n",
       " 'layers.0.feed_forward',\n",
       " 'layers.0.feed_forward.w1',\n",
       " 'layers.0.feed_forward.w2',\n",
       " 'layers.0.feed_forward.w3',\n",
       " 'layers.0.attention_norm',\n",
       " 'layers.0.ffn_norm',\n",
       " 'layers.1',\n",
       " 'layers.1.attention',\n",
       " 'layers.1.attention.wq',\n",
       " 'layers.1.attention.wk',\n",
       " 'layers.1.attention.wv',\n",
       " 'layers.1.attention.wo',\n",
       " 'layers.1.feed_forward',\n",
       " 'layers.1.feed_forward.w1',\n",
       " 'layers.1.feed_forward.w2',\n",
       " 'layers.1.feed_forward.w3',\n",
       " 'layers.1.attention_norm',\n",
       " 'layers.1.ffn_norm',\n",
       " 'layers.2',\n",
       " 'layers.2.attention',\n",
       " 'layers.2.attention.wq',\n",
       " 'layers.2.attention.wk',\n",
       " 'layers.2.attention.wv',\n",
       " 'layers.2.attention.wo',\n",
       " 'layers.2.feed_forward',\n",
       " 'layers.2.feed_forward.w1',\n",
       " 'layers.2.feed_forward.w2',\n",
       " 'layers.2.feed_forward.w3',\n",
       " 'layers.2.attention_norm',\n",
       " 'layers.2.ffn_norm',\n",
       " 'layers.3',\n",
       " 'layers.3.attention',\n",
       " 'layers.3.attention.wq',\n",
       " 'layers.3.attention.wk',\n",
       " 'layers.3.attention.wv',\n",
       " 'layers.3.attention.wo',\n",
       " 'layers.3.feed_forward',\n",
       " 'layers.3.feed_forward.w1',\n",
       " 'layers.3.feed_forward.w2',\n",
       " 'layers.3.feed_forward.w3',\n",
       " 'layers.3.attention_norm',\n",
       " 'layers.3.ffn_norm',\n",
       " 'layers.4',\n",
       " 'layers.4.attention',\n",
       " 'layers.4.attention.wq',\n",
       " 'layers.4.attention.wk',\n",
       " 'layers.4.attention.wv',\n",
       " 'layers.4.attention.wo',\n",
       " 'layers.4.feed_forward',\n",
       " 'layers.4.feed_forward.w1',\n",
       " 'layers.4.feed_forward.w2',\n",
       " 'layers.4.feed_forward.w3',\n",
       " 'layers.4.attention_norm',\n",
       " 'layers.4.ffn_norm',\n",
       " 'layers.5',\n",
       " 'layers.5.attention',\n",
       " 'layers.5.attention.wq',\n",
       " 'layers.5.attention.wk',\n",
       " 'layers.5.attention.wv',\n",
       " 'layers.5.attention.wo',\n",
       " 'layers.5.feed_forward',\n",
       " 'layers.5.feed_forward.w1',\n",
       " 'layers.5.feed_forward.w2',\n",
       " 'layers.5.feed_forward.w3',\n",
       " 'layers.5.attention_norm',\n",
       " 'layers.5.ffn_norm',\n",
       " 'layers.6',\n",
       " 'layers.6.attention',\n",
       " 'layers.6.attention.wq',\n",
       " 'layers.6.attention.wk',\n",
       " 'layers.6.attention.wv',\n",
       " 'layers.6.attention.wo',\n",
       " 'layers.6.feed_forward',\n",
       " 'layers.6.feed_forward.w1',\n",
       " 'layers.6.feed_forward.w2',\n",
       " 'layers.6.feed_forward.w3',\n",
       " 'layers.6.attention_norm',\n",
       " 'layers.6.ffn_norm',\n",
       " 'layers.7',\n",
       " 'layers.7.attention',\n",
       " 'layers.7.attention.wq',\n",
       " 'layers.7.attention.wk',\n",
       " 'layers.7.attention.wv',\n",
       " 'layers.7.attention.wo',\n",
       " 'layers.7.feed_forward',\n",
       " 'layers.7.feed_forward.w1',\n",
       " 'layers.7.feed_forward.w2',\n",
       " 'layers.7.feed_forward.w3',\n",
       " 'layers.7.attention_norm',\n",
       " 'layers.7.ffn_norm',\n",
       " 'layers.8',\n",
       " 'layers.8.attention',\n",
       " 'layers.8.attention.wq',\n",
       " 'layers.8.attention.wk',\n",
       " 'layers.8.attention.wv',\n",
       " 'layers.8.attention.wo',\n",
       " 'layers.8.feed_forward',\n",
       " 'layers.8.feed_forward.w1',\n",
       " 'layers.8.feed_forward.w2',\n",
       " 'layers.8.feed_forward.w3',\n",
       " 'layers.8.attention_norm',\n",
       " 'layers.8.ffn_norm',\n",
       " 'layers.9',\n",
       " 'layers.9.attention',\n",
       " 'layers.9.attention.wq',\n",
       " 'layers.9.attention.wk',\n",
       " 'layers.9.attention.wv',\n",
       " 'layers.9.attention.wo',\n",
       " 'layers.9.feed_forward',\n",
       " 'layers.9.feed_forward.w1',\n",
       " 'layers.9.feed_forward.w2',\n",
       " 'layers.9.feed_forward.w3',\n",
       " 'layers.9.attention_norm',\n",
       " 'layers.9.ffn_norm',\n",
       " 'layers.10',\n",
       " 'layers.10.attention',\n",
       " 'layers.10.attention.wq',\n",
       " 'layers.10.attention.wk',\n",
       " 'layers.10.attention.wv',\n",
       " 'layers.10.attention.wo',\n",
       " 'layers.10.feed_forward',\n",
       " 'layers.10.feed_forward.w1',\n",
       " 'layers.10.feed_forward.w2',\n",
       " 'layers.10.feed_forward.w3',\n",
       " 'layers.10.attention_norm',\n",
       " 'layers.10.ffn_norm',\n",
       " 'layers.11',\n",
       " 'layers.11.attention',\n",
       " 'layers.11.attention.wq',\n",
       " 'layers.11.attention.wk',\n",
       " 'layers.11.attention.wv',\n",
       " 'layers.11.attention.wo',\n",
       " 'layers.11.feed_forward',\n",
       " 'layers.11.feed_forward.w1',\n",
       " 'layers.11.feed_forward.w2',\n",
       " 'layers.11.feed_forward.w3',\n",
       " 'layers.11.attention_norm',\n",
       " 'layers.11.ffn_norm',\n",
       " 'layers.12',\n",
       " 'layers.12.attention',\n",
       " 'layers.12.attention.wq',\n",
       " 'layers.12.attention.wk',\n",
       " 'layers.12.attention.wv',\n",
       " 'layers.12.attention.wo',\n",
       " 'layers.12.feed_forward',\n",
       " 'layers.12.feed_forward.w1',\n",
       " 'layers.12.feed_forward.w2',\n",
       " 'layers.12.feed_forward.w3',\n",
       " 'layers.12.attention_norm',\n",
       " 'layers.12.ffn_norm',\n",
       " 'layers.13',\n",
       " 'layers.13.attention',\n",
       " 'layers.13.attention.wq',\n",
       " 'layers.13.attention.wk',\n",
       " 'layers.13.attention.wv',\n",
       " 'layers.13.attention.wo',\n",
       " 'layers.13.feed_forward',\n",
       " 'layers.13.feed_forward.w1',\n",
       " 'layers.13.feed_forward.w2',\n",
       " 'layers.13.feed_forward.w3',\n",
       " 'layers.13.attention_norm',\n",
       " 'layers.13.ffn_norm',\n",
       " 'layers.14',\n",
       " 'layers.14.attention',\n",
       " 'layers.14.attention.wq',\n",
       " 'layers.14.attention.wk',\n",
       " 'layers.14.attention.wv',\n",
       " 'layers.14.attention.wo',\n",
       " 'layers.14.feed_forward',\n",
       " 'layers.14.feed_forward.w1',\n",
       " 'layers.14.feed_forward.w2',\n",
       " 'layers.14.feed_forward.w3',\n",
       " 'layers.14.attention_norm',\n",
       " 'layers.14.ffn_norm',\n",
       " 'layers.15',\n",
       " 'layers.15.attention',\n",
       " 'layers.15.attention.wq',\n",
       " 'layers.15.attention.wk',\n",
       " 'layers.15.attention.wv',\n",
       " 'layers.15.attention.wo',\n",
       " 'layers.15.feed_forward',\n",
       " 'layers.15.feed_forward.w1',\n",
       " 'layers.15.feed_forward.w2',\n",
       " 'layers.15.feed_forward.w3',\n",
       " 'layers.15.attention_norm',\n",
       " 'layers.15.ffn_norm',\n",
       " 'layers.16',\n",
       " 'layers.16.attention',\n",
       " 'layers.16.attention.wq',\n",
       " 'layers.16.attention.wk',\n",
       " 'layers.16.attention.wv',\n",
       " 'layers.16.attention.wo',\n",
       " 'layers.16.feed_forward',\n",
       " 'layers.16.feed_forward.w1',\n",
       " 'layers.16.feed_forward.w2',\n",
       " 'layers.16.feed_forward.w3',\n",
       " 'layers.16.attention_norm',\n",
       " 'layers.16.ffn_norm',\n",
       " 'layers.17',\n",
       " 'layers.17.attention',\n",
       " 'layers.17.attention.wq',\n",
       " 'layers.17.attention.wk',\n",
       " 'layers.17.attention.wv',\n",
       " 'layers.17.attention.wo',\n",
       " 'layers.17.feed_forward',\n",
       " 'layers.17.feed_forward.w1',\n",
       " 'layers.17.feed_forward.w2',\n",
       " 'layers.17.feed_forward.w3',\n",
       " 'layers.17.attention_norm',\n",
       " 'layers.17.ffn_norm',\n",
       " 'layers.18',\n",
       " 'layers.18.attention',\n",
       " 'layers.18.attention.wq',\n",
       " 'layers.18.attention.wk',\n",
       " 'layers.18.attention.wv',\n",
       " 'layers.18.attention.wo',\n",
       " 'layers.18.feed_forward',\n",
       " 'layers.18.feed_forward.w1',\n",
       " 'layers.18.feed_forward.w2',\n",
       " 'layers.18.feed_forward.w3',\n",
       " 'layers.18.attention_norm',\n",
       " 'layers.18.ffn_norm',\n",
       " 'layers.19',\n",
       " 'layers.19.attention',\n",
       " 'layers.19.attention.wq',\n",
       " 'layers.19.attention.wk',\n",
       " 'layers.19.attention.wv',\n",
       " 'layers.19.attention.wo',\n",
       " 'layers.19.feed_forward',\n",
       " 'layers.19.feed_forward.w1',\n",
       " 'layers.19.feed_forward.w2',\n",
       " 'layers.19.feed_forward.w3',\n",
       " 'layers.19.attention_norm',\n",
       " 'layers.19.ffn_norm',\n",
       " 'layers.20',\n",
       " 'layers.20.attention',\n",
       " 'layers.20.attention.wq',\n",
       " 'layers.20.attention.wk',\n",
       " 'layers.20.attention.wv',\n",
       " 'layers.20.attention.wo',\n",
       " 'layers.20.feed_forward',\n",
       " 'layers.20.feed_forward.w1',\n",
       " 'layers.20.feed_forward.w2',\n",
       " 'layers.20.feed_forward.w3',\n",
       " 'layers.20.attention_norm',\n",
       " 'layers.20.ffn_norm',\n",
       " 'layers.21',\n",
       " 'layers.21.attention',\n",
       " 'layers.21.attention.wq',\n",
       " 'layers.21.attention.wk',\n",
       " 'layers.21.attention.wv',\n",
       " 'layers.21.attention.wo',\n",
       " 'layers.21.feed_forward',\n",
       " 'layers.21.feed_forward.w1',\n",
       " 'layers.21.feed_forward.w2',\n",
       " 'layers.21.feed_forward.w3',\n",
       " 'layers.21.attention_norm',\n",
       " 'layers.21.ffn_norm',\n",
       " 'layers.22',\n",
       " 'layers.22.attention',\n",
       " 'layers.22.attention.wq',\n",
       " 'layers.22.attention.wk',\n",
       " 'layers.22.attention.wv',\n",
       " 'layers.22.attention.wo',\n",
       " 'layers.22.feed_forward',\n",
       " 'layers.22.feed_forward.w1',\n",
       " 'layers.22.feed_forward.w2',\n",
       " 'layers.22.feed_forward.w3',\n",
       " 'layers.22.attention_norm',\n",
       " 'layers.22.ffn_norm',\n",
       " 'layers.23',\n",
       " 'layers.23.attention',\n",
       " 'layers.23.attention.wq',\n",
       " 'layers.23.attention.wk',\n",
       " 'layers.23.attention.wv',\n",
       " 'layers.23.attention.wo',\n",
       " 'layers.23.feed_forward',\n",
       " 'layers.23.feed_forward.w1',\n",
       " 'layers.23.feed_forward.w2',\n",
       " 'layers.23.feed_forward.w3',\n",
       " 'layers.23.attention_norm',\n",
       " 'layers.23.ffn_norm',\n",
       " 'layers.24',\n",
       " 'layers.24.attention',\n",
       " 'layers.24.attention.wq',\n",
       " 'layers.24.attention.wk',\n",
       " 'layers.24.attention.wv',\n",
       " 'layers.24.attention.wo',\n",
       " 'layers.24.feed_forward',\n",
       " 'layers.24.feed_forward.w1',\n",
       " 'layers.24.feed_forward.w2',\n",
       " 'layers.24.feed_forward.w3',\n",
       " 'layers.24.attention_norm',\n",
       " 'layers.24.ffn_norm',\n",
       " 'layers.25',\n",
       " 'layers.25.attention',\n",
       " 'layers.25.attention.wq',\n",
       " 'layers.25.attention.wk',\n",
       " 'layers.25.attention.wv',\n",
       " 'layers.25.attention.wo',\n",
       " 'layers.25.feed_forward',\n",
       " 'layers.25.feed_forward.w1',\n",
       " 'layers.25.feed_forward.w2',\n",
       " 'layers.25.feed_forward.w3',\n",
       " 'layers.25.attention_norm',\n",
       " 'layers.25.ffn_norm',\n",
       " 'layers.26',\n",
       " 'layers.26.attention',\n",
       " 'layers.26.attention.wq',\n",
       " 'layers.26.attention.wk',\n",
       " 'layers.26.attention.wv',\n",
       " 'layers.26.attention.wo',\n",
       " 'layers.26.feed_forward',\n",
       " 'layers.26.feed_forward.w1',\n",
       " 'layers.26.feed_forward.w2',\n",
       " 'layers.26.feed_forward.w3',\n",
       " 'layers.26.attention_norm',\n",
       " 'layers.26.ffn_norm',\n",
       " 'layers.27',\n",
       " 'layers.27.attention',\n",
       " 'layers.27.attention.wq',\n",
       " 'layers.27.attention.wk',\n",
       " 'layers.27.attention.wv',\n",
       " 'layers.27.attention.wo',\n",
       " 'layers.27.feed_forward',\n",
       " 'layers.27.feed_forward.w1',\n",
       " 'layers.27.feed_forward.w2',\n",
       " 'layers.27.feed_forward.w3',\n",
       " 'layers.27.attention_norm',\n",
       " 'layers.27.ffn_norm',\n",
       " 'layers.28',\n",
       " 'layers.28.attention',\n",
       " 'layers.28.attention.wq',\n",
       " 'layers.28.attention.wk',\n",
       " 'layers.28.attention.wv',\n",
       " 'layers.28.attention.wo',\n",
       " 'layers.28.feed_forward',\n",
       " 'layers.28.feed_forward.w1',\n",
       " 'layers.28.feed_forward.w2',\n",
       " 'layers.28.feed_forward.w3',\n",
       " 'layers.28.attention_norm',\n",
       " 'layers.28.ffn_norm',\n",
       " 'layers.29',\n",
       " 'layers.29.attention',\n",
       " 'layers.29.attention.wq',\n",
       " 'layers.29.attention.wk',\n",
       " 'layers.29.attention.wv',\n",
       " 'layers.29.attention.wo',\n",
       " 'layers.29.feed_forward',\n",
       " 'layers.29.feed_forward.w1',\n",
       " 'layers.29.feed_forward.w2',\n",
       " 'layers.29.feed_forward.w3',\n",
       " 'layers.29.attention_norm',\n",
       " 'layers.29.ffn_norm',\n",
       " 'layers.30',\n",
       " 'layers.30.attention',\n",
       " 'layers.30.attention.wq',\n",
       " 'layers.30.attention.wk',\n",
       " 'layers.30.attention.wv',\n",
       " 'layers.30.attention.wo',\n",
       " 'layers.30.feed_forward',\n",
       " 'layers.30.feed_forward.w1',\n",
       " 'layers.30.feed_forward.w2',\n",
       " 'layers.30.feed_forward.w3',\n",
       " 'layers.30.attention_norm',\n",
       " 'layers.30.ffn_norm',\n",
       " 'layers.31',\n",
       " 'layers.31.attention',\n",
       " 'layers.31.attention.wq',\n",
       " 'layers.31.attention.wk',\n",
       " 'layers.31.attention.wv',\n",
       " 'layers.31.attention.wo',\n",
       " 'layers.31.feed_forward',\n",
       " 'layers.31.feed_forward.w1',\n",
       " 'layers.31.feed_forward.w2',\n",
       " 'layers.31.feed_forward.w3',\n",
       " 'layers.31.attention_norm',\n",
       " 'layers.31.ffn_norm',\n",
       " 'layers.32',\n",
       " 'layers.32.attention',\n",
       " 'layers.32.attention.wq',\n",
       " 'layers.32.attention.wk',\n",
       " 'layers.32.attention.wv',\n",
       " 'layers.32.attention.wo',\n",
       " 'layers.32.feed_forward',\n",
       " 'layers.32.feed_forward.w1',\n",
       " 'layers.32.feed_forward.w2',\n",
       " 'layers.32.feed_forward.w3',\n",
       " 'layers.32.attention_norm',\n",
       " 'layers.32.ffn_norm',\n",
       " 'layers.33',\n",
       " 'layers.33.attention',\n",
       " 'layers.33.attention.wq',\n",
       " 'layers.33.attention.wk',\n",
       " 'layers.33.attention.wv',\n",
       " 'layers.33.attention.wo',\n",
       " 'layers.33.feed_forward',\n",
       " 'layers.33.feed_forward.w1',\n",
       " 'layers.33.feed_forward.w2',\n",
       " 'layers.33.feed_forward.w3',\n",
       " 'layers.33.attention_norm',\n",
       " 'layers.33.ffn_norm',\n",
       " 'layers.34',\n",
       " 'layers.34.attention',\n",
       " 'layers.34.attention.wq',\n",
       " 'layers.34.attention.wk',\n",
       " 'layers.34.attention.wv',\n",
       " 'layers.34.attention.wo',\n",
       " 'layers.34.feed_forward',\n",
       " 'layers.34.feed_forward.w1',\n",
       " 'layers.34.feed_forward.w2',\n",
       " 'layers.34.feed_forward.w3',\n",
       " 'layers.34.attention_norm',\n",
       " 'layers.34.ffn_norm',\n",
       " 'layers.35',\n",
       " 'layers.35.attention',\n",
       " 'layers.35.attention.wq',\n",
       " 'layers.35.attention.wk',\n",
       " 'layers.35.attention.wv',\n",
       " 'layers.35.attention.wo',\n",
       " 'layers.35.feed_forward',\n",
       " 'layers.35.feed_forward.w1',\n",
       " 'layers.35.feed_forward.w2',\n",
       " 'layers.35.feed_forward.w3',\n",
       " 'layers.35.attention_norm',\n",
       " 'layers.35.ffn_norm',\n",
       " 'layers.36',\n",
       " 'layers.36.attention',\n",
       " 'layers.36.attention.wq',\n",
       " 'layers.36.attention.wk',\n",
       " 'layers.36.attention.wv',\n",
       " 'layers.36.attention.wo',\n",
       " 'layers.36.feed_forward',\n",
       " 'layers.36.feed_forward.w1',\n",
       " 'layers.36.feed_forward.w2',\n",
       " 'layers.36.feed_forward.w3',\n",
       " 'layers.36.attention_norm',\n",
       " 'layers.36.ffn_norm',\n",
       " 'layers.37',\n",
       " 'layers.37.attention',\n",
       " 'layers.37.attention.wq',\n",
       " 'layers.37.attention.wk',\n",
       " 'layers.37.attention.wv',\n",
       " 'layers.37.attention.wo',\n",
       " 'layers.37.feed_forward',\n",
       " 'layers.37.feed_forward.w1',\n",
       " 'layers.37.feed_forward.w2',\n",
       " 'layers.37.feed_forward.w3',\n",
       " 'layers.37.attention_norm',\n",
       " 'layers.37.ffn_norm',\n",
       " 'layers.38',\n",
       " 'layers.38.attention',\n",
       " 'layers.38.attention.wq',\n",
       " 'layers.38.attention.wk',\n",
       " 'layers.38.attention.wv',\n",
       " 'layers.38.attention.wo',\n",
       " 'layers.38.feed_forward',\n",
       " 'layers.38.feed_forward.w1',\n",
       " 'layers.38.feed_forward.w2',\n",
       " 'layers.38.feed_forward.w3',\n",
       " 'layers.38.attention_norm',\n",
       " 'layers.38.ffn_norm',\n",
       " 'layers.39',\n",
       " 'layers.39.attention',\n",
       " 'layers.39.attention.wq',\n",
       " 'layers.39.attention.wk',\n",
       " 'layers.39.attention.wv',\n",
       " 'layers.39.attention.wo',\n",
       " 'layers.39.feed_forward',\n",
       " 'layers.39.feed_forward.w1',\n",
       " 'layers.39.feed_forward.w2',\n",
       " 'layers.39.feed_forward.w3',\n",
       " 'layers.39.attention_norm',\n",
       " 'layers.39.ffn_norm',\n",
       " 'norm',\n",
       " 'output']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the module names of interest and pass them into a `get_activations` function alongside our set of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations(activations=[{'layers.0': tensor([[ 0.0464,  0.0161,  0.0542,  ...,  0.0118,  0.0105, -0.0007],\n",
      "        [ 0.0547, -0.0118,  0.0457,  ...,  0.0460, -0.0007, -0.0750],\n",
      "        [-0.0071, -0.0102,  0.0236,  ...,  0.0019,  0.0247, -0.0515]],\n",
      "       dtype=torch.float16)}, {'layers.0': tensor([[ 0.0464,  0.0161,  0.0542,  ...,  0.0118,  0.0105, -0.0007],\n",
      "        [ 0.0225,  0.0150,  0.0426,  ...,  0.0200,  0.0557, -0.0128],\n",
      "        [ 0.0478,  0.0051, -0.0265,  ..., -0.0123, -0.0550, -0.0129],\n",
      "        [ 0.0308, -0.0104,  0.0361,  ...,  0.0083,  0.0245,  0.0138],\n",
      "        [ 0.0372,  0.0225,  0.0079,  ..., -0.0589, -0.0757, -0.0204]],\n",
      "       dtype=torch.float16)}], logprobs=[[-2.024453639984131], [-1.995332956314087]], sequences=[',', 'in'], tokens=[[','], ['in']])\n",
      "Tensor Shape: torch.Size([3, 5120])\n",
      "Tensor Shape: torch.Size([5, 5120])\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"Hello World\", \"Fizz Buzz\"]\n",
    "\n",
    "module_name = \"layers.0\"\n",
    "\n",
    "activations = model.get_activations(prompts, [module_name], generation_config)\n",
    "pprint(activations)\n",
    "\n",
    "# We sent a batch of 2 prompts to the model.\n",
    "# So a list of length two is returned containing activations for the requested layer\n",
    "for activations_single_prompt in activations.activations:\n",
    "    # For each prompt we extract the activations associated with the target module.\n",
    "    raw_activations = activations_single_prompt[module_name]\n",
    "    # The activations should have shape (number of tokens + 1) x (activation size)\n",
    "    # For example, LLaMA-13B has an embedding dimension for the layer requested of 5120\n",
    "    print(\"Tensor Shape:\", raw_activations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__: In the code below, we're going to only use batch sizes of 1 to ensure memory management on the backend doesn't get out of hand and slow the model down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Tokens: [1, 383, 4981, 350, 18813]\n",
      "Decoded Tokens: ['<s>', 'F', 'izz', 'B', 'uzz']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer prepares the input of the model. LLaMA models of all sizes use the same underlying tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/david/Desktop/LLaMA2_Tokenizer\")\n",
    "# Let's test out how the tokenizer works on an example sentence. Note that the token with ID = 1 is the\n",
    "# Beginning of sentence token (\"BOS\")\n",
    "encoded_tokens = tokenizer.encode(\"Fizz Buzz\")\n",
    "print(f\"Encoded Tokens: {encoded_tokens}\")\n",
    "# If you ever need to move back from token ids, you can use tokenizer.decode or tokenizer.batch_decode\n",
    "decoded_tokens = [tokenizer.decode(encoded_token) for encoded_token in encoded_tokens]\n",
    "print(f\"Decoded Tokens: {decoded_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the second example, \"Fizz Buzz\", is tokenized as [\"F\", \"izz\", \"B\", 'uzz]. So we receive a tensor with 5 rows (one for each token and a final one for the next token to be generated) and 5120 columns (the hidden dimension of LLaMA-2-13B)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a proof of concept of the few-shot abilities of LLMs, we'll only use a small training dataset and will only perform validation using a small test subset for compute efficiency.\n",
    "\n",
    "* Training set: 100 randomly sampled training examples\n",
    "* Test set: 300 randomly sample test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "imdb = datasets.load_dataset(\"imdb\")\n",
    "train_size = 100\n",
    "test_size = 300\n",
    "n_demonstrations = 5\n",
    "\n",
    "activation_save_path = \"./resources/llama2_13b_activations\"\n",
    "\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(train_size))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(test_size))])\n",
    "# We're going to be experimenting with the affect that prompting the model for the task we care about has on a\n",
    "# classifier trained on the activations in terms of performance. So we will construct demonstrations by randomly\n",
    "# selecting a set of 5 examples from the training set to serve this purpose.\n",
    "small_demonstration_set = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(n_demonstrations))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a list into a tuple of lists of a fixed size\n",
    "def batcher(prompts: List[str], batch_size: int) -> Dataset:\n",
    "    return (prompts[pos : pos + batch_size] for pos in range(0, len(prompts), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're running a lot of activation retrievals. Once in a while there is a json decoding or triton error. If that\n",
    "# happens, we retry the activations request.\n",
    "def get_activations_with_retries(prompt: str, layers: List[str], config: Dict[str, Any], retries: int = 5) -> Any:\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            return model.get_activations(prompt, layers, config)\n",
    "        except Exception as e:  # noqa: F841\n",
    "            print(\"Something went wrong in activation retrieval...retrying\")\n",
    "    raise ValueError(\"Exceeded retry limit. Exiting Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_input_text(text: str, truncation_length: int) -> str:\n",
    "    # If text is longer than truncation length, split by space, take the last truncation_length tokens\n",
    "    split_text = text.split(\" \")\n",
    "    if len(split_text) > truncation_length:\n",
    "        text = \" \".join(split_text[-truncation_length:])\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Text Activations\n",
    "\n",
    "Let's start by getting the activations associated with the raw review text. We'll do activations for the text coupled with a prompt below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_activations(\n",
    "    split: str,\n",
    "    inputs: List[str],\n",
    "    labels: List[int],\n",
    "    module_name: str,\n",
    "    pickle_name: str,\n",
    ") -> None:\n",
    "    print(\"Generating Activations with Prompts: \" + split)\n",
    "\n",
    "    parsed_activations = []\n",
    "    # Using a batch size of 1 as activation fetching is heavy\n",
    "    for batch_num, input_batch in enumerate(batcher(inputs, 1)):\n",
    "        # Getting activations for each input batch. For an example of how get_activations works, see beginning of this\n",
    "        # notebook.\n",
    "        input_batch = [truncate_input_text(input, 256) for input in input_batch]\n",
    "        raw_activations = get_activations_with_retries(input_batch, [module_name], generation_config).activations\n",
    "        for raw_activation in raw_activations:\n",
    "            # We will be performing classification on the last token non-pad token of the sequence. This is common\n",
    "            # practice for auto-regressive models (e.g. OPT, Falcon, LLaMA-2). So we only keep the last row of the\n",
    "            # activation matrix.\n",
    "            parsed_activations.append(raw_activation[module_name][-1].float())\n",
    "        if (batch_num + 1) % 50 == 0:\n",
    "            print(f\"Batch {batch_num+1} Completed\")\n",
    "\n",
    "    cached_activations = {\"activations\": parsed_activations, \"labels\": labels}\n",
    "\n",
    "    with open(os.path.join(activation_save_path, f\"{split}{pickle_name}.pkl\"), \"wb\") as handle:\n",
    "        pickle.dump(cached_activations, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Activations for Module Name layers.20\n",
      "Generating Activations with Prompts: train\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Batch 50 Completed\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Batch 100 Completed\n",
      "Generating Activations with Prompts: test\n",
      "Something went wrong in activation retrieval...retrying\n",
      "Something went wrong in activation retrieval...retrying\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration Activations for Module Name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m generate_dataset_activations(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, small_train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_labels, module_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_activations_demo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mgenerate_dataset_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_test_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_activations_demo_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer_number\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mgenerate_dataset_activations\u001b[0;34m(split, inputs, labels, module_name, pickle_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num, input_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batcher(inputs, \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Getting activations for each input batch. For an example of how get_activations works, see beginning of this\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# notebook.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     input_batch \u001b[38;5;241m=\u001b[39m [truncate_input_text(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m256\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_batch]\n\u001b[0;32m---> 16\u001b[0m     raw_activations \u001b[38;5;241m=\u001b[39m \u001b[43mget_activations_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mactivations\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_activation \u001b[38;5;129;01min\u001b[39;00m raw_activations:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# We will be performing classification on the last token non-pad token of the sequence. This is common\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# practice for auto-regressive models (e.g. OPT, Falcon, LLaMA-2). So we only keep the last row of the\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# activation matrix.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         parsed_activations\u001b[38;5;241m.\u001b[39mappend(raw_activation[module_name][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mget_activations_with_retries\u001b[0;34m(prompt, layers, config, retries)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomething went wrong in activation retrieval...retrying\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/kscope/kaleidoscope_sdk.py:278\u001b[0m, in \u001b[0;36mModel.get_activations\u001b[0;34m(self, prompts, modules, generation_config)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompts, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    277\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [prompts]\n\u001b[0;32m--> 278\u001b[0m activations_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(activations_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m elm \u001b[38;5;129;01min\u001b[39;00m activations_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx]:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/kscope/kaleidoscope_sdk.py:194\u001b[0m, in \u001b[0;36mGatewaySession.get_activations\u001b[0;34m(self, model_instance_id, prompts, modules, generation_config)\u001b[0m\n\u001b[1;32m    185\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_addr(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/instances/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_instance_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/get_activations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m )\n\u001b[1;32m    188\u001b[0m body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompts\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompts,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodules\u001b[39m\u001b[38;5;124m\"\u001b[39m: modules,\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation_config,\n\u001b[1;32m    192\u001b[0m }\n\u001b[0;32m--> 194\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/kscope/utils.py:63\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(addr, body, auth_key, headers)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth_key:\n\u001b[1;32m     61\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauth_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 63\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m check_response(resp)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/prompt_engineering/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer_numbers = [\"20\", \"30\", \"39\"]\n",
    "module_names = [f\"layers.{layer_number}\" for layer_number in layer_numbers]\n",
    "\n",
    "train_labels = small_train_dataset[\"label\"]\n",
    "test_labels = small_test_dataset[\"label\"]\n",
    "\n",
    "assert len(module_names) == len(layer_numbers)\n",
    "\n",
    "for module_name, layer_number in zip(module_names, layer_numbers):\n",
    "    print(f\"Generation Activations for Module Name {module_name}\")\n",
    "    generate_dataset_activations(\n",
    "        \"train\", small_train_dataset[\"text\"], train_labels, module_name, f\"_activations_demo_{layer_number}\"\n",
    "    )\n",
    "    generate_dataset_activations(\n",
    "        \"test\", small_test_dataset[\"text\"], test_labels, module_name, f\"_activations_demo_{layer_number}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Conditioned Activations\n",
    "\n",
    "Now let's generate activations pre-conditioned with an instruction and a few demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demonstrations(instruction: str, demonstration_set: Dataset) -> str:\n",
    "    label_int_to_str = {0: \"negative\", 1: \"positive\"}\n",
    "    demonstration = f\"{instruction}\"\n",
    "    demo_texts = demonstration_set[\"text\"]\n",
    "    demo_labels = demonstration_set[\"label\"]\n",
    "    for text, label in zip(demo_texts, demo_labels):\n",
    "        # truncate the text in case it is very long (cutting the first part of text)\n",
    "        text = truncate_input_text(text, 64)\n",
    "        demonstration = f\"{demonstration}\\nText: {text}\\nSentiment: {label_int_to_str[label]}\"\n",
    "    return f\"{demonstration}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts(texts: List[str], demonstration: str) -> List[str]:\n",
    "    truncated_texts = [truncate_input_text(text, 128) for text in texts]\n",
    "    return [f\"{demonstration}Text: {text} The sentiment is\" for text in truncated_texts]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the demonstration structure (based on 5 examples) and what each prompt passed to OPT looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration:\n",
      "Classify the sentiment of the text.\n",
      "Text: like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...\n",
      "Sentiment: positive\n",
      "Text: favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.\n",
      "Sentiment: positive\n",
      "Text: comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\n",
      "Sentiment: negative\n",
      "Text: employ a political spoils system. There's nothing noble in that. The Missourians could have easily traveled east and joined the Confederate Army.<br /><br />It seems to me that the story has nothing to do with ambiguity. When Jake leaves the Bushwhackers, it's not because he saw error in his way, he certainly doesn't give himself over to the virtue of the cause of abolition.\n",
      "Sentiment: positive\n",
      "Text: this finally drives home the film's other big flaw: lack of originality. In this review, I realize it's been far too easy to reference many other films. Granted, this film is an improvement on most of them, but still. *The Secret Lives of Dentists* is worth seeing, but don't get too excited about it. (Not that you were all that excited, anyway. I guess.)\n",
      "Sentiment: negative\n",
      "\n",
      "Prompt Example:\n",
      "Classify the sentiment of the text.\n",
      "Text: like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...\n",
      "Sentiment: positive\n",
      "Text: favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.\n",
      "Sentiment: positive\n",
      "Text: comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\n",
      "Sentiment: negative\n",
      "Text: employ a political spoils system. There's nothing noble in that. The Missourians could have easily traveled east and joined the Confederate Army.<br /><br />It seems to me that the story has nothing to do with ambiguity. When Jake leaves the Bushwhackers, it's not because he saw error in his way, he certainly doesn't give himself over to the virtue of the cause of abolition.\n",
      "Sentiment: positive\n",
      "Text: this finally drives home the film's other big flaw: lack of originality. In this review, I realize it's been far too easy to reference many other films. Granted, this film is an improvement on most of them, but still. *The Secret Lives of Dentists* is worth seeing, but don't get too excited about it. (Not that you were all that excited, anyway. I guess.)\n",
      "Sentiment: negative\n",
      "Text: There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all... The sentiment is\n"
     ]
    }
   ],
   "source": [
    "demonstration = create_demonstrations(\"Classify the sentiment of the text.\", small_demonstration_set)\n",
    "print(f\"Demonstration:\\n{demonstration}\")\n",
    "\n",
    "train_prompts = create_prompts(small_train_dataset[\"text\"], demonstration)\n",
    "test_prompts = create_prompts(small_test_dataset[\"text\"], demonstration)\n",
    "print(f\"Prompt Example:\\n{train_prompts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Activations for Module Name layers.10\n",
      "Generating Activations with Prompts: train\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Generating Activations with Prompts: test\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Batch 150 Completed\n",
      "Batch 200 Completed\n",
      "Batch 250 Completed\n",
      "Batch 300 Completed\n",
      "Generation Activations for Module Name layers.20\n",
      "Generating Activations with Prompts: train\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Generating Activations with Prompts: test\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Batch 150 Completed\n",
      "Batch 200 Completed\n",
      "Batch 250 Completed\n",
      "Batch 300 Completed\n",
      "Generation Activations for Module Name layers.30\n",
      "Generating Activations with Prompts: train\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Generating Activations with Prompts: test\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Batch 150 Completed\n",
      "Batch 200 Completed\n",
      "Batch 250 Completed\n",
      "Batch 300 Completed\n",
      "Generation Activations for Module Name layers.39\n",
      "Generating Activations with Prompts: train\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Generating Activations with Prompts: test\n",
      "Batch 50 Completed\n",
      "Batch 100 Completed\n",
      "Batch 150 Completed\n",
      "Batch 200 Completed\n",
      "Batch 250 Completed\n",
      "Batch 300 Completed\n"
     ]
    }
   ],
   "source": [
    "layer_numbers = [\"10\", \"20\", \"30\", \"39\"]\n",
    "module_names = [f\"layers.{layer_number}\" for layer_number in layer_numbers]\n",
    "\n",
    "train_labels = small_train_dataset[\"label\"]\n",
    "test_labels = small_test_dataset[\"label\"]\n",
    "\n",
    "assert len(module_names) == len(layer_numbers)\n",
    "\n",
    "for module_name, layer_number in zip(module_names, layer_numbers):\n",
    "    print(f\"Generation Activations for Module Name {module_name}\")\n",
    "    generate_dataset_activations(\n",
    "        \"train\", train_prompts, train_labels, module_name, f\"_activations_with_prompts_demo_{layer_number}\"\n",
    "    )\n",
    "    generate_dataset_activations(\n",
    "        \"test\",\n",
    "        test_prompts,\n",
    "        test_labels,\n",
    "        module_name,\n",
    "        f\"_activations_with_prompts_demo_{layer_number}\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these activations saved, the next step is to train a simple classifier on top of them in order to perform the sentiment classification. This is done in the `train_on_activations.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_fine_tune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
